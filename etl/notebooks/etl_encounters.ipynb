{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling for encounters.csv\n",
    "This notebook processes the `encounters.csv` by performing the following steps:\n",
    "- Inspecting and cleaning the data\n",
    "- Handling missing values and inconsistencies\n",
    "- Transforming the data (e.g., creating new features)\n",
    "- Saving the processed data to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing Column Names\n",
    "def func_rename_and_cast_columns(df, column_mappings):\n",
    "    '''\n",
    "    Applies column_mappings to the columns of input dataframe\n",
    "\n",
    "    df: Input dataframe\n",
    "    column_mappings: dictionary containing mappings for column names        \n",
    "    '''\n",
    "    list_unnormalised_colnames = df.columns.to_list()\n",
    "    for unnormalised_colname in list_unnormalised_colnames:\n",
    "        normalised_colname = column_mappings[unnormalised_colname]['normalised_colname']\n",
    "        col_type = column_mappings[unnormalised_colname]['type']\n",
    "        print(f\"renaming column: {unnormalised_colname} to {normalised_colname} and casting type to: {col_type}\")\n",
    "        df.rename(columns={unnormalised_colname: normalised_colname}, inplace=True)\n",
    "        if col_type == 'str':\n",
    "            # Fill NAs and empty strings to \"unknowns\"\n",
    "            if df[normalised_colname].isnull().any() or df[normalised_colname].isna().any():\n",
    "                print(f\"column: {normalised_colname} contains null values thus filling with unknown\")\n",
    "                df[normalised_colname] = df[normalised_colname].fillna(\"Unknown\")\n",
    "            df[normalised_colname] = df[normalised_colname].astype(str)\n",
    "            print(f\"{normalised_colname} casted to type(str)\")\n",
    "        if col_type == 'datetimestamp':\n",
    "            # df[normalised_colname] = pd.to_datetime(df[normalised_colname], errors='coerce')\n",
    "            df[normalised_colname] = pd.to_datetime(df[normalised_colname], errors='coerce') \n",
    "            df[normalised_colname] = df[normalised_colname].dt.tz_localize(None) # Retaining source timeformat\n",
    "            print(f\"{normalised_colname} casted to datetime\")\n",
    "        if col_type == 'numeric':\n",
    "            df[normalised_colname] = pd.to_numeric(df[normalised_colname], errors='coerce')\n",
    "            print(f\"{normalised_colname} casted to numeric\")\n",
    "        print('-'*5)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "filepath_csv = '../../data/raw_data/encounters.csv' # Read CSV \n",
    "filepath_processed_csv = '../../data/processed_data/processed_encounters.csv' # Write processed CSV\n",
    "filepath_yaml = '../../config/encounters.yaml' # Read encounters.yaml, it is used to clean column names and apply relevant types to columns\n",
    "\n",
    "# Load Dataframe\n",
    "df_encounters = pd.read_csv(filepath_csv)\n",
    "# Load YAML column mappings \n",
    "with open(filepath_yaml, \"r\") as file:\n",
    "    dict_column_mappings = yaml.safe_load(file)\n",
    "    \n",
    "# Display initial dataset information\n",
    "print('Initial Dataset Info:')\n",
    "df_encounters.info()\n",
    "df_encounters.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Data Quality Checks\n",
    "\n",
    "1. Standardise column names\n",
    "2. Apply relevant types\n",
    "3. Fill null values with relevant values\n",
    "4. Perform the logical testing (start_time < end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encounters = func_rename_and_cast_columns(df_encounters, dict_column_mappings['encounters'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
